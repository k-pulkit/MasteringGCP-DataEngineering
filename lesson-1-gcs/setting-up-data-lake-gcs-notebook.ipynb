{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Cloud Storage using Python and Pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using gsutil inside the notebook using !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://gcs-data-lake-1/data/\n"
     ]
    }
   ],
   "source": [
    "!gsutil list gs://gcs-data-lake-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://gcs-data-lake-1/data/:\n",
      "\n",
      "gs://gcs-data-lake-1/data/retail_db/:\n",
      "gs://gcs-data-lake-1/data/retail_db/create_db_tables_pg.sql\n",
      "gs://gcs-data-lake-1/data/retail_db/load_db_tables_pg.sql\n",
      "gs://gcs-data-lake-1/data/retail_db/schemas.json\n",
      "\n",
      "gs://gcs-data-lake-1/data/retail_db/categories/:\n",
      "gs://gcs-data-lake-1/data/retail_db/categories/part-00000\n",
      "\n",
      "gs://gcs-data-lake-1/data/retail_db/customers/:\n",
      "gs://gcs-data-lake-1/data/retail_db/customers/part-00000\n",
      "\n",
      "gs://gcs-data-lake-1/data/retail_db/departments/:\n",
      "gs://gcs-data-lake-1/data/retail_db/departments/part-00000\n",
      "\n",
      "gs://gcs-data-lake-1/data/retail_db/order_items/:\n",
      "gs://gcs-data-lake-1/data/retail_db/order_items/part-00000\n",
      "\n",
      "gs://gcs-data-lake-1/data/retail_db/orders/:\n",
      "gs://gcs-data-lake-1/data/retail_db/orders/part-00000\n",
      "\n",
      "gs://gcs-data-lake-1/data/retail_db/products/:\n",
      "gs://gcs-data-lake-1/data/retail_db/products/part-00000\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls -R gs://gcs-data-lake-1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Python to interact with Google Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By using the below command, it sets the application defaults for the GCS Python library to connect to google cloud\n",
    "\n",
    "!gcloud auth application-default login"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a client to Google Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.storage.client.Client at 0x7f2373bdfbb0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "gsclient = storage.Client()\n",
    "gsclient"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List all the buckets in the account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buckets in the account are [<Bucket: gcs-data-lake-1>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'gcs-data-lake-1'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Buckets in the account are {list(gsclient.list_buckets())}\")\n",
    "\n",
    "bucket0 = list(gsclient.list_buckets())[0]\n",
    "bucket0.name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List all blobs in current bucket and show contents of one of the blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Blob: gcs-data-lake-1, data/retail_db/categories/part-00000, 1676193065875141>\n",
      "<Blob: gcs-data-lake-1, data/retail_db/create_db_tables_pg.sql, 1676193065836272>\n",
      "<Blob: gcs-data-lake-1, data/retail_db/customers/part-00000, 1676193065868069>\n",
      "<Blob: gcs-data-lake-1, data/retail_db/departments/part-00000, 1676193065828750>\n",
      "<Blob: gcs-data-lake-1, data/retail_db/load_db_tables_pg.sql, 1676193065865869>\n",
      "<Blob: gcs-data-lake-1, data/retail_db/order_items/part-00000, 1676193065874727>\n",
      "<Blob: gcs-data-lake-1, data/retail_db/orders/part-00000, 1676193065904849>\n",
      "<Blob: gcs-data-lake-1, data/retail_db/products/part-00000, 1676193065917054>\n",
      "<Blob: gcs-data-lake-1, data/retail_db/schemas.json, 1676193065864417>\n"
     ]
    }
   ],
   "source": [
    "for i in bucket0.list_blobs():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'departments': [{'column_name': 'department_id',\n",
       "   'data_type': 'integer',\n",
       "   'column_position': 1},\n",
       "  {'column_name': 'department_name',\n",
       "   'data_type': 'string',\n",
       "   'column_position': 2}],\n",
       " 'categories': [{'column_name': 'category_id',\n",
       "   'data_type': 'integer',\n",
       "   'column_position': 1},\n",
       "  {'column_name': 'category_department_id',\n",
       "   'data_type': 'integer',\n",
       "   'column_position': 2},\n",
       "  {'column_name': 'category_name',\n",
       "   'data_type': 'string',\n",
       "   'column_position': 3}],\n",
       " 'orders': [{'column_name': 'order_id',\n",
       "   'data_type': 'integer',\n",
       "   'column_position': 1},\n",
       "  {'column_name': 'order_date', 'data_type': 'string', 'column_position': 2},\n",
       "  {'column_name': 'order_customer_id',\n",
       "   'data_type': 'timestamp',\n",
       "   'column_position': 3},\n",
       "  {'column_name': 'order_status',\n",
       "   'data_type': 'string',\n",
       "   'column_position': 4}],\n",
       " 'products': [{'column_name': 'product_id',\n",
       "   'data_type': 'integer',\n",
       "   'column_position': 1},\n",
       "  {'column_name': 'product_cateogry_id',\n",
       "   'data_type': 'integer',\n",
       "   'column_position': 2},\n",
       "  {'column_name': 'product_name', 'data_type': '', 'column_position': 3},\n",
       "  {'column_name': 'product_description',\n",
       "   'data_type': 'string',\n",
       "   'column_position': 4},\n",
       "  {'column_name': 'product_price', 'data_type': 'float', 'column_position': 5},\n",
       "  {'column_name': 'product_image',\n",
       "   'data_type': 'string',\n",
       "   'column_position': 6}],\n",
       " 'customers': [{'column_name': 'customer_id',\n",
       "   'data_type': 'integer',\n",
       "   'column_position': 1},\n",
       "  {'column_name': 'customer_fname',\n",
       "   'data_type': 'string',\n",
       "   'column_position': 2},\n",
       "  {'column_name': 'customer_lname',\n",
       "   'data_type': 'string',\n",
       "   'column_position': 3},\n",
       "  {'column_name': 'customer_email',\n",
       "   'data_type': 'string',\n",
       "   'column_position': 4},\n",
       "  {'column_name': 'customer_password',\n",
       "   'data_type': 'string',\n",
       "   'column_position': 5},\n",
       "  {'column_name': 'customer_street',\n",
       "   'data_type': 'string',\n",
       "   'column_position': 6},\n",
       "  {'column_name': 'customer_city',\n",
       "   'data_type': 'string',\n",
       "   'column_position': 7},\n",
       "  {'column_name': 'customer_state',\n",
       "   'data_type': 'string',\n",
       "   'column_position': 8},\n",
       "  {'column_name': 'customer_zipcode',\n",
       "   'data_type': 'integer',\n",
       "   'column_position': 9}],\n",
       " 'order_items': [{'column_name': 'order_item_id',\n",
       "   'data_type': 'integer',\n",
       "   'column_position': 1},\n",
       "  {'column_name': 'order_item_order_id',\n",
       "   'data_type': 'integer',\n",
       "   'column_position': 2},\n",
       "  {'column_name': 'order_item_product_id',\n",
       "   'data_type': 'integer',\n",
       "   'column_position': 3},\n",
       "  {'column_name': 'order_item_quantity',\n",
       "   'data_type': 'integer',\n",
       "   'column_position': 4},\n",
       "  {'column_name': 'order_item_subtotal',\n",
       "   'data_type': 'float',\n",
       "   'column_position': 5},\n",
       "  {'column_name': 'order_item_product_price',\n",
       "   'data_type': 'float',\n",
       "   'column_position': 6}]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the last object in memory, which is \"schemas.json\"\n",
    "\n",
    "json.loads(i.download_as_string())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting a specific bucket, and working with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/retail_db/categories/part-00000',\n",
       " 'data/retail_db/create_db_tables_pg.sql',\n",
       " 'data/retail_db/customers/part-00000',\n",
       " 'data/retail_db/departments/part-00000',\n",
       " 'data/retail_db/load_db_tables_pg.sql',\n",
       " 'data/retail_db/order_items/part-00000',\n",
       " 'data/retail_db/orders/part-00000',\n",
       " 'data/retail_db/products/part-00000',\n",
       " 'data/retail_db/schemas.json']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.name for i in gsclient.get_bucket(bucket_or_name=\"gcs-data-lake-1\").list_blobs()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating new blobs of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new blob, and deleting\n",
    "gsclient.get_bucket(bucket_or_name=\"gcs-data-lake-1\").blob(\"new_blob\").upload_from_string(\"This is a new blob\")\n",
    "gsclient.get_bucket(bucket_or_name=\"gcs-data-lake-1\").blob(\"new_blob\").exists()\n",
    "gsclient.get_bucket(bucket_or_name=\"gcs-data-lake-1\").blob(\"new_blob\").delete()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting as blob, downloading data and displaying with Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Blob: gcs-data-lake-1, data/retail_db/orders/part-00000, 1676193065904849>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_name =  \"data/retail_db/orders/part-00000\"\n",
    "blob = gsclient.get_bucket(\"gcs-data-lake-1\").get_blob(blob_name)\n",
    "blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-07-25 00:00:00.0</td>\n",
       "      <td>11599</td>\n",
       "      <td>CLOSED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-07-25 00:00:00.0</td>\n",
       "      <td>256</td>\n",
       "      <td>PENDING_PAYMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-07-25 00:00:00.0</td>\n",
       "      <td>12111</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                      1      2                3\n",
       "0  1  2013-07-25 00:00:00.0  11599           CLOSED\n",
       "1  2  2013-07-25 00:00:00.0    256  PENDING_PAYMENT\n",
       "2  3  2013-07-25 00:00:00.0  12111         COMPLETE"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "io = BytesIO()\n",
    "\n",
    "io.write(blob.download_as_string())\n",
    "io.seek(0)\n",
    "pd.read_csv(io, header=None).head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Downloading with URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-07-25 00:00:00.0</td>\n",
       "      <td>11599</td>\n",
       "      <td>CLOSED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-07-25 00:00:00.0</td>\n",
       "      <td>256</td>\n",
       "      <td>PENDING_PAYMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-07-25 00:00:00.0</td>\n",
       "      <td>12111</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                      1      2                3\n",
       "0  1  2013-07-25 00:00:00.0  11599           CLOSED\n",
       "1  2  2013-07-25 00:00:00.0    256  PENDING_PAYMENT\n",
       "2  3  2013-07-25 00:00:00.0  12111         COMPLETE"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "io = BytesIO()\n",
    "gsclient.download_blob_to_file(\"gs://gcs-data-lake-1/data/retail_db/orders/part-00000\", io)\n",
    "io.seek(0)\n",
    "pd.read_csv(io, header=None).head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project to upload multiple files to GCS using Python modules\n",
    "\n",
    "As part of this section, we will be using the modules like google-cloud-storage, OS and glob to enable us to transfer files from local to the object storage with help of Python API\n",
    " \n",
    "Design requirements - \n",
    "1. Get list of file names from local\n",
    "2. Build a blob for each file to upload\n",
    "3. use upload method to upload the related data\n",
    "4. use metadata for help with uploading the right info\n",
    "5. rename blobs with help of file names as reference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://test-data-lake-1/...\n"
     ]
    }
   ],
   "source": [
    "!gsutil mb -b on -c standard --autoclass --placement us-east1,us-east4 gs://test-data-lake-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Bucket: gcs-data-lake-1>, <Bucket: test-data-lake-1>]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(gsclient.list_buckets())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, now we have two buckets, with the one we recently created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cards/smalldecks/deckofcards.txt', 'cards/smalldecks/deckofcards.tar.gz']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Function to get list of all the files that we require\n",
    "\n",
    "from glob import glob\n",
    "from os import path\n",
    "\n",
    "def get_file_list(src_dir):\n",
    "    items = glob(f\"{src_dir}/**\", recursive=True)\n",
    "    for i in filter(lambda item: path.isfile(item), items): yield i\n",
    "\n",
    "create_blob_name = lambda x: x[x.index(\"/\", x.index(\"/\")+1)+1:]\n",
    "[create_blob_name(i) for i in get_file_list(\"../data/\")][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload of file in progress - cards/smalldecks/deckofcards.txt\n",
      "Upload of file in progress - cards/smalldecks/deckofcards.tar.gz\n",
      "Upload of file in progress - cards/deckofcards.txt\n",
      "Upload of file in progress - cards/zippeddecks/zippeddeck.txt.gz\n",
      "Upload of file in progress - cards/zippeddecks/zippeddeck.tar\n",
      "Upload of file in progress - cards/largedeck.txt.gz\n",
      "Upload of file in progress - electionresults/ls2014.tsv\n",
      "Upload of file in progress - nyse/companylist_noheader.csv\n",
      "Upload of file in progress - nyse/nyse_data.tar.gz\n",
      "Upload of file in progress - nyse_all/nyse_data/NYSE_2004.txt.gz\n",
      "Upload of file in progress - nyse_all/nyse_data/NYSE_2013.txt.gz\n",
      "Upload of file in progress - nyse_all/nyse_data/NYSE_2011.txt.gz\n",
      "Upload of file in progress - nyse_all/nyse_data/NYSE_2009.txt.gz\n",
      "Upload of file in progress - nyse_all/nyse_data/NYSE_1998.txt.gz\n",
      "Upload of file in progress - nyse_all/nyse_data/NYSE_2003.txt.gz\n",
      "Upload of file in progress - nyse_all/nyse_data/NYSE_2014.txt.gz\n",
      "Upload of file in progress - nyse_all/nyse_data/NYSE_2005.txt.gz\n",
      "Upload of file in progress - nyse_all/nyse_data/NYSE_2012.txt.gz\n",
      "Upload of file in progress - nyse_all/nyse_data/NYSE_2006.txt.gz\n",
      "Upload of file in progress - nyse_all/nyse_data/NYSE_2015.txt.gz\n",
      "Upload of file in progress - nyse_all/nyse_data/NYSE_2007.txt.gz\n",
      "Upload of file in progress - nyse_all/nyse_data/NYSE_2016.txt.gz\n",
      "Upload of file in progress - nyse_all/nyse_data/NYSE_1997.txt.gz\n",
      "Upload of file in progress - nyse_all/nyse_data/NYSE_2001.txt.gz\n",
      "Upload of file in progress - nyse_all/nyse_data/NYSE_2008.txt.gz\n",
      "Upload of file in progress - nyse_all/nyse_data/NYSE_1999.txt.gz\n",
      "Upload of file in progress - nyse_all/nyse_data/NYSE_2000.txt.gz\n",
      "Upload of file in progress - nyse_all/nyse_data/NYSE_2010.txt.gz\n",
      "Upload of file in progress - nyse_all/nyse_data/NYSE_2017.txt.gz\n",
      "Upload of file in progress - nyse_all/nyse_data/NYSE_2002.txt.gz\n",
      "Upload of file in progress - nyse_all/nyse_stocks/companylist_noheader.csv\n",
      "Upload of file in progress - README.md\n",
      "Upload of file in progress - hr/hr_mysql.sql\n",
      "Upload of file in progress - retail_db_json/orders/part-r-00000-990f5773-9005-49ba-b670-631286032674\n",
      "Upload of file in progress - retail_db_json/order_items/part-r-00000-6b83977e-3f20-404b-9b5f-29376ab1419e\n",
      "Upload of file in progress - retail_db_json/categories/part-r-00000-ce1d8208-178d-48d3-bfb2-1a97d9c05094\n",
      "Upload of file in progress - retail_db_json/products/part-r-00000-158b7037-4a23-47e6-8cb3-8cbf878beff7\n",
      "Upload of file in progress - retail_db_json/customers/part-r-00000-70554560-527b-44f6-9e80-4e2031af5994\n",
      "Upload of file in progress - retail_db_json/departments/part-r-00000-3db7cfae-3ad2-4fc7-88ff-afe0ec709f49\n",
      "Upload of file in progress - retail_db_header/orders/part-00000\n",
      "Upload of file in progress - retail_db_header/order_items/part-00000\n",
      "Upload of file in progress - retail_db_header/categories/part-00000\n",
      "Upload of file in progress - retail_db_header/products/part-00000\n",
      "Upload of file in progress - retail_db_header/customers/part-00000\n",
      "Upload of file in progress - retail_db_header/departments/part-00000\n",
      "Upload of file in progress - lca/LCA_FY2013.csv.gz\n",
      "Upload of file in progress - lca/LCA_FY2011.csv.gz\n",
      "Upload of file in progress - lca/LCA_FY2010.csv.gz\n",
      "Upload of file in progress - lca/LCA_FY2012.csv.gz\n",
      "Upload of file in progress - retail_db/load_db_tables_pg.sql\n",
      "Upload of file in progress - retail_db/orders/part-00000\n",
      "Upload of file in progress - retail_db/order_items/part-00000\n",
      "Upload of file in progress - retail_db/schemas.json\n",
      "Upload of file in progress - retail_db/categories/part-00000\n",
      "Upload of file in progress - retail_db/create_db_tables_pg.sql\n",
      "Upload of file in progress - retail_db/products/part-00000\n",
      "Upload of file in progress - retail_db/customers/part-00000\n",
      "Upload of file in progress - retail_db/departments/part-00000\n",
      "Upload of file in progress - hr_db/locations/part-m-00000\n",
      "Upload of file in progress - hr_db/locations/part-m-00003\n",
      "Upload of file in progress - hr_db/locations/part-m-00002\n",
      "Upload of file in progress - hr_db/locations/part-m-00001\n",
      "Upload of file in progress - hr_db/job_history/part-m-00000\n",
      "Upload of file in progress - hr_db/job_history/part-m-00003\n",
      "Upload of file in progress - hr_db/jobs/part-m-00003\n",
      "Upload of file in progress - hr_db/jobs/part-m-00004\n",
      "Upload of file in progress - hr_db/jobs/part-m-00002\n",
      "Upload of file in progress - hr_db/jobs/part-m-00001\n",
      "Upload of file in progress - hr_db/employees/part-00000.csv\n",
      "Upload of file in progress - hr_db/regions/part-m-00000\n",
      "Upload of file in progress - hr_db/regions/part-m-00003\n",
      "Upload of file in progress - hr_db/regions/part-m-00002\n",
      "Upload of file in progress - hr_db/regions/part-m-00001\n",
      "Upload of file in progress - hr_db/countries/part-m-00000\n",
      "Upload of file in progress - hr_db/countries/part-m-00003\n",
      "Upload of file in progress - hr_db/countries/part-m-00002\n",
      "Upload of file in progress - hr_db/countries/part-m-00001\n",
      "Upload of file in progress - hr_db/departments/part-m-00000\n",
      "Upload of file in progress - hr_db/departments/part-m-00003\n",
      "Upload of file in progress - hr_db/departments/part-m-00002\n",
      "Upload of file in progress - hr_db/departments/part-m-00001\n",
      "Upload of file in progress - hr_db/emp_details_view/part-m-00000\n"
     ]
    }
   ],
   "source": [
    "### Let's upload these files to bucket we created\n",
    "\n",
    "bucket1 = gsclient.get_bucket(bucket_or_name=\"test-data-lake-1\")\n",
    "for file_to_upload in get_file_list(\"../data/\"):\n",
    "    # Get the file object\n",
    "    blob_name=create_blob_name(file_to_upload)\n",
    "    blob = bucket1.blob(blob_name=blob_name)\n",
    "    with open(file_to_upload, \"rb\") as f:\n",
    "        print(f\"Upload of file in progress - {blob_name}\")\n",
    "        blob.upload_from_file(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(bucket1.list_blobs()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Blob: test-data-lake-1, retail_db/categories/part-00000, 1676239099401336>,\n",
       " <Blob: test-data-lake-1, retail_db/create_db_tables_pg.sql, 1676239099920951>,\n",
       " <Blob: test-data-lake-1, retail_db/customers/part-00000, 1676239101051780>,\n",
       " <Blob: test-data-lake-1, retail_db/departments/part-00000, 1676239101592531>,\n",
       " <Blob: test-data-lake-1, retail_db/load_db_tables_pg.sql, 1676239096202400>,\n",
       " <Blob: test-data-lake-1, retail_db/order_items/part-00000, 1676239098325463>,\n",
       " <Blob: test-data-lake-1, retail_db/orders/part-00000, 1676239097434223>,\n",
       " <Blob: test-data-lake-1, retail_db/products/part-00000, 1676239100453811>,\n",
       " <Blob: test-data-lake-1, retail_db/schemas.json, 1676239098876624>]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another way of listing the files of interest\n",
    "\n",
    "list(gsclient.list_blobs(bucket_or_name=\"test-data-lake-1\", prefix=\"retail_db/\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of using pandas to process the files in GCS\n",
    "\n",
    "In order to achieve this, we will be using a python library called `gcsfs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>order_customer_id</th>\n",
       "      <th>order_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-07-25 00:00:00.0</td>\n",
       "      <td>11599</td>\n",
       "      <td>CLOSED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-07-25 00:00:00.0</td>\n",
       "      <td>256</td>\n",
       "      <td>PENDING_PAYMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-07-25 00:00:00.0</td>\n",
       "      <td>12111</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id             order_date  order_customer_id     order_status\n",
       "0         1  2013-07-25 00:00:00.0              11599           CLOSED\n",
       "1         2  2013-07-25 00:00:00.0                256  PENDING_PAYMENT\n",
       "2         3  2013-07-25 00:00:00.0              12111         COMPLETE"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Because gcsfs is installed, we can directly specify the location with GCS to access the table\n",
    "df_order_details = pd.read_csv(\"gs://test-data-lake-1/retail_db/orders/part-00000\", names=[\"order_id\", \"order_date\", \"order_customer_id\", \"order_status\"])\n",
    "df_order_details.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing parquet files to GCS (compressed and partitioned) and then reading them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the data to GFS\n",
    "df_order_details.to_parquet(\"gs://test-data-lake-1/retail_db_parquet/orders/part-00000.snappy.parquet\", compression=\"snappy\", partition_cols=[\"order_status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Blob: test-data-lake-1, retail_db_parquet/orders/part-00000.snappy.parquet/order_status=CANCELED/aff7d2fc3e744710812a01af8fc1942c-0.parquet, 1676240825523613>,\n",
       " <Blob: test-data-lake-1, retail_db_parquet/orders/part-00000.snappy.parquet/order_status=CLOSED/aff7d2fc3e744710812a01af8fc1942c-0.parquet, 1676240825522819>,\n",
       " <Blob: test-data-lake-1, retail_db_parquet/orders/part-00000.snappy.parquet/order_status=COMPLETE/aff7d2fc3e744710812a01af8fc1942c-0.parquet, 1676240825606102>,\n",
       " <Blob: test-data-lake-1, retail_db_parquet/orders/part-00000.snappy.parquet/order_status=ON_HOLD/aff7d2fc3e744710812a01af8fc1942c-0.parquet, 1676240826036880>,\n",
       " <Blob: test-data-lake-1, retail_db_parquet/orders/part-00000.snappy.parquet/order_status=PAYMENT_REVIEW/aff7d2fc3e744710812a01af8fc1942c-0.parquet, 1676240825481703>,\n",
       " <Blob: test-data-lake-1, retail_db_parquet/orders/part-00000.snappy.parquet/order_status=PENDING/aff7d2fc3e744710812a01af8fc1942c-0.parquet, 1676240825557637>,\n",
       " <Blob: test-data-lake-1, retail_db_parquet/orders/part-00000.snappy.parquet/order_status=PENDING_PAYMENT/aff7d2fc3e744710812a01af8fc1942c-0.parquet, 1676240825802570>,\n",
       " <Blob: test-data-lake-1, retail_db_parquet/orders/part-00000.snappy.parquet/order_status=PROCESSING/aff7d2fc3e744710812a01af8fc1942c-0.parquet, 1676240825575619>,\n",
       " <Blob: test-data-lake-1, retail_db_parquet/orders/part-00000.snappy.parquet/order_status=SUSPECTED_FRAUD/aff7d2fc3e744710812a01af8fc1942c-0.parquet, 1676240825949130>]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(gsclient.list_blobs(\"test-data-lake-1\", prefix=\"retail_db_parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>order_customer_id</th>\n",
       "      <th>order_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>2013-07-25 00:00:00.0</td>\n",
       "      <td>5225</td>\n",
       "      <td>CANCELED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112</td>\n",
       "      <td>2013-07-26 00:00:00.0</td>\n",
       "      <td>5375</td>\n",
       "      <td>CANCELED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>527</td>\n",
       "      <td>2013-07-28 00:00:00.0</td>\n",
       "      <td>5426</td>\n",
       "      <td>CANCELED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>552</td>\n",
       "      <td>2013-07-28 00:00:00.0</td>\n",
       "      <td>1445</td>\n",
       "      <td>CANCELED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>564</td>\n",
       "      <td>2013-07-28 00:00:00.0</td>\n",
       "      <td>2216</td>\n",
       "      <td>CANCELED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68878</th>\n",
       "      <td>68606</td>\n",
       "      <td>2014-06-28 00:00:00.0</td>\n",
       "      <td>2253</td>\n",
       "      <td>SUSPECTED_FRAUD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68879</th>\n",
       "      <td>68686</td>\n",
       "      <td>2014-07-23 00:00:00.0</td>\n",
       "      <td>2591</td>\n",
       "      <td>SUSPECTED_FRAUD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68880</th>\n",
       "      <td>68718</td>\n",
       "      <td>2013-09-14 00:00:00.0</td>\n",
       "      <td>6710</td>\n",
       "      <td>SUSPECTED_FRAUD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68881</th>\n",
       "      <td>68782</td>\n",
       "      <td>2014-01-10 00:00:00.0</td>\n",
       "      <td>8509</td>\n",
       "      <td>SUSPECTED_FRAUD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68882</th>\n",
       "      <td>68865</td>\n",
       "      <td>2014-06-19 00:00:00.0</td>\n",
       "      <td>4567</td>\n",
       "      <td>SUSPECTED_FRAUD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68883 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       order_id             order_date  order_customer_id     order_status\n",
       "0            50  2013-07-25 00:00:00.0               5225         CANCELED\n",
       "1           112  2013-07-26 00:00:00.0               5375         CANCELED\n",
       "2           527  2013-07-28 00:00:00.0               5426         CANCELED\n",
       "3           552  2013-07-28 00:00:00.0               1445         CANCELED\n",
       "4           564  2013-07-28 00:00:00.0               2216         CANCELED\n",
       "...         ...                    ...                ...              ...\n",
       "68878     68606  2014-06-28 00:00:00.0               2253  SUSPECTED_FRAUD\n",
       "68879     68686  2014-07-23 00:00:00.0               2591  SUSPECTED_FRAUD\n",
       "68880     68718  2013-09-14 00:00:00.0               6710  SUSPECTED_FRAUD\n",
       "68881     68782  2014-01-10 00:00:00.0               8509  SUSPECTED_FRAUD\n",
       "68882     68865  2014-06-19 00:00:00.0               4567  SUSPECTED_FRAUD\n",
       "\n",
       "[68883 rows x 4 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the shape of the data file written to GCS\n",
    "pd.read_parquet(\"gs://test-data-lake-1/retail_db_parquet/orders/part-00000.snappy.parquet\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project to upload multiple files to GCS using Python modules -USING PANDAS\n",
    "\n",
    "As part of this section, we will be using the modules like google-cloud-storage, OS and glob to enable us to transfer files from local to the object storage with help of Python API\n",
    " \n",
    "Design requirements - \n",
    "1. Get list of file names from local\n",
    "2. Build a blob for each file to upload\n",
    "3. use upload method to upload the related data\n",
    "4. use metadata for help with uploading the right info\n",
    "5. rename blobs with help of file names as reference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First delete all blobs, specially the parquet\n",
    "\n",
    "# delete\n",
    "bucket1.delete_blobs(list(bucket1.list_blobs()))\n",
    "# validate\n",
    "list(bucket1.list_blobs())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the files written in previous step have been deleted. The next step is to write a generic function to read the files, convert and transfer to the GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in bucket1.list_blobs():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['retail_db/orders/part-00000',\n",
       " 'retail_db/order_items/part-00000',\n",
       " 'retail_db/categories/part-00000',\n",
       " 'retail_db/products/part-00000',\n",
       " 'retail_db/customers/part-00000',\n",
       " 'retail_db/departments/part-00000']"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_file_list(src_dir):\n",
    "    items = glob(f\"{src_dir}/**\", recursive=True)\n",
    "    for i in filter(lambda item: path.isfile(item) and item.endswith(\"part-00000\"), items) : yield i\n",
    "\n",
    "create_blob_name = lambda x: x[x.index(\"/\", x.index(\"/\")+1)+1:]\n",
    "[create_blob_name(i) for i in get_file_list(\"../data/retail_db\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file retail_db_parquet/orders/part-00000.snappy.parquet\n",
      "Uploaded file retail_db_parquet/order_items/part-00000.snappy.parquet\n",
      "Uploaded file retail_db_parquet/categories/part-00000.snappy.parquet\n",
      "Uploaded file retail_db_parquet/products/part-00000.snappy.parquet\n",
      "Uploaded file retail_db_parquet/customers/part-00000.snappy.parquet\n",
      "Uploaded file retail_db_parquet/departments/part-00000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "# Read the schema\n",
    "with open(\"../data/retail_db/schemas.json\") as f:\n",
    "    schemax = json.load(f)\n",
    "\n",
    "for file_to_upload in get_file_list(\"../data/retail_db/\"):\n",
    "    blob_name = create_blob_name(file_to_upload)\n",
    "    blob_name = f'{blob_name.split(\"/\")[0]}_parquet/' + \"/\".join(blob_name.split(\"/\")[1:])\n",
    "    \n",
    "    table_name = blob_name.split(\"/\")[1]\n",
    "    schema = pd.DataFrame(schemax[table_name]).sort_values(\"column_position\")\n",
    "    col_names = schema.column_name\n",
    "    \n",
    "    df = pd.read_csv(file_to_upload, names=col_names)\n",
    "    df.to_parquet(f\"gs://test-data-lake-1/{blob_name}.snappy.parquet\", compression=\"snappy\")\n",
    "    print(f\"Uploaded file {blob_name}.snappy.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_cateogry_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_description</th>\n",
       "      <th>product_price</th>\n",
       "      <th>product_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Quest Q64 10 FT. x 10 FT. Slant Leg Instant U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.98</td>\n",
       "      <td>http://images.acmesports.sports/Quest+Q64+10+F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Under Armour Men's Highlight MC Football Clea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129.99</td>\n",
       "      <td>http://images.acmesports.sports/Under+Armour+M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Under Armour Men's Renegade D Mid Football Cl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.99</td>\n",
       "      <td>http://images.acmesports.sports/Under+Armour+M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Under Armour Men's Renegade D Mid Football Cl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.99</td>\n",
       "      <td>http://images.acmesports.sports/Under+Armour+M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Riddell Youth Revolution Speed Custom Footbal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>199.99</td>\n",
       "      <td>http://images.acmesports.sports/Riddell+Youth+...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  product_cateogry_id  \\\n",
       "0           1                    2   \n",
       "1           2                    2   \n",
       "2           3                    2   \n",
       "3           4                    2   \n",
       "4           5                    2   \n",
       "\n",
       "                                    product_name  product_description  \\\n",
       "0  Quest Q64 10 FT. x 10 FT. Slant Leg Instant U                  NaN   \n",
       "1  Under Armour Men's Highlight MC Football Clea                  NaN   \n",
       "2  Under Armour Men's Renegade D Mid Football Cl                  NaN   \n",
       "3  Under Armour Men's Renegade D Mid Football Cl                  NaN   \n",
       "4  Riddell Youth Revolution Speed Custom Footbal                  NaN   \n",
       "\n",
       "   product_price                                      product_image  \n",
       "0          59.98  http://images.acmesports.sports/Quest+Q64+10+F...  \n",
       "1         129.99  http://images.acmesports.sports/Under+Armour+M...  \n",
       "2          89.99  http://images.acmesports.sports/Under+Armour+M...  \n",
       "3          89.99  http://images.acmesports.sports/Under+Armour+M...  \n",
       "4         199.99  http://images.acmesports.sports/Riddell+Youth+...  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read a file to see if column names are picked up\n",
    "pd.read_parquet(\"gs://test-data-lake-1/retail_db_parquet/products/part-00000.snappy.parquet\").head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END OF SECTION"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcp-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "94db1dcbbacddcbe7c309f195a130791f4943678ca16027e61a31b19b569e969"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
